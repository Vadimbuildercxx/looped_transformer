wandb:
    project: Lets_Loop2
    notes: looped ssm 1 layer b = 1 L = 1
    log_every_steps: 100


gpu:
    cuda: True
    n_gpu: 0
model:
    family: ssm_gpt2
    n_embd: 256
    n_layer: 1
    d_state: 32
    n_dims: 10
    n_positions: 101
    last_n_tokens: null

training:
    seed: null
    batch_size: 64
    task_name: linear_regression
    learning_rate: 0.008
    weight_decay: 0.0
    train_steps: 15000
    save_every_steps: 1000
    keep_every_steps: 100000
    curriculum:
        dims:
            start: 10
            end: 10
            inc: 0
            interval: 10000
        points:
            start: 31
            end: 31
            inc: 0
            interval: 10000
        loops:
            start: 1
            end: 1
            inc: 0
            interval: 500
    n_loop_window: 20

out_dir: ./results2/linear_regression_loop
debug_mode: False