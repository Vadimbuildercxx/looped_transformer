## Some ideas about research

- [ ] Check attention heads for linearity or gradient descent properties.
- [ ] Try to replace gradient descent with other optimization algos.
- [ ] Check for loss landscape with compare to linear regression.
- [ ] Try to make some parameters learnable (example: lr)
- [ ] Compare with ordinary TF like in paper.

## Questions

- [ ] What about arbitrary loop count in every iteration (Gates maybe)
- [ ] What is Weight Tying?
- [ ] Explain this sentence  Furthermore, as denoted in Eq. 1, the loss is truncated, with only the outputs of T loop
  iterations contributing to the loss function.

