{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Отчет по исследованию Looped Transformers и их возможностей.\n",
    "Мини исследование-отчет по статье - https://arxiv.org/abs/2311.12424"
   ],
   "id": "723d8026c8091484"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Сравнение эффективности Looped TFs с обычными TFs\n",
    "Все эксперементы проводились с выключенным Mixed Precision, по скольку он не влиял на скорость обучения - видимо из-за того что gpt2_nano не может использовать GPU эффективно.\n",
    "Одна часть эксперементов проводилась на локальной машине с Nvidia 3060ti mobile, а вторая на удаленной машине с Nvidia Tesla P100."
   ],
   "id": "a99812fd98be8c89"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Посмотрим на скорость сходимости трансформера (TF) с параметром $ L = 12 $ и Looped TFs с параметрами $ L = 1; b = \\{5, 10, 20, 25\\} T= \\{10, 20\\}$. Были использованы следующие параметры Heads=4, dims=10, points=31. Потери масштабированы на размерность регрессии.\n",
    "\n",
    "|                                                    |                                               |\n",
    "|----------------------------------------------------|-----------------------------------------------|\n",
    "| ![](../images/Compare_losses_b_n_t_10.png \"Title\") | ![](../images/Compare_losses_b_n.png \"Title\") |\n",
    "\n",
    "Как можно видеть из графиков, Looped TFs при увеличении $ b $ дает улучшение метрик. При количестве параметров в 12 раз меньшим, чем у обычного трансформера, он показывает неплохие показатели. Конфигурации для запуска моделей взяты из папки эксперимента №5."
   ],
   "id": "18f797d1aa385c1a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Итеративные свойства\n",
    "По скольку в статье подразумевается что Looped TFs имеют итеративные свойства, мы можем их проверить на примере линейной регрессии.\n",
    "Для этого обучим Looped TFs со значениями $ b=\\{5, 10, 20\\}; T=\\{ 20, 10\\} $  и посмотрим на их сходимость при больших $ b $.\n",
    "\n",
    "|           |       |\n",
    "|-----------|-------|\n",
    "| ![alt text](../images/check_for_convergence_properties.png \"Title\")    | ![alt text](../images/check_for_scheduling_convergence_properties_noisy_linear_regression_T_10_short.png \"Title\") |\n",
    "\n",
    "Из графика можем видеть что при большем $ b $ на тренировке Looped TF показывает себя лучше при $ b > 5 $.  Блокнот `experiment_schedule.ipynb`. \n"
   ],
   "id": "5f5f89b0bfcfce2f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ac650dd477d79314"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Дополнительно\n",
    "Появилась гипотеза о том, что шедулинг может помочь для обобщающих способностей модели. Увеличивая параметр $ b $ во время тренировки можно получить лучшую обобщающую способность, однако в процессе эксперимента со слабыми моделями это явно не подтвердилось. При тренировке с вариативным & b & и , модель дает меньшую ошибку на большем количестве итераций при $ T=20 $, однако при $ T=10 $ утверждать то же не можем.  Опыты проводились в блокноте `experiment_shedule.ipynb` и в блокноте `experiment_shedule_2.ipynb`.\n",
    "\n",
    "|           |                                                                                              |\n",
    "|-----------|----------------------------------------------------------------------------------------------|\n",
    "| ![](../images/check_for_scheduling_convergence_properties.png \"Title\")    | ![](../images/check_for_scheduling_convergence_properties_train_steps_10000.png \"Title\")     |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Из графика можно видеть, что в отличии от моделей с параметрами $ b=5; b=10; b=15 $, у модели с варьированием $ b $ на этапе тренировки показатели точности сильно разнятся. "
   ],
   "id": "d87a8f3275d84722"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Попробуем брать только N последних токенов\n",
    "Проверим гипотезу\n",
    "\n",
    "> ***Гипотеза***\n",
    "> \n",
    "> В таком случае, модель имеет возможность использовать часть токенов как хранилище информации с предыдущего шага.\n",
    "\n",
    "Чтобы понять на сколько мы можем обрезать количество токенов которые подаются модель замаскируем часть из них и посмотрим на метрики.\n"
   ],
   "id": "19658e4437a1ac08"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "На графиках ниже мы можем видеть вполне ожидаемый результат, для моделей с $ b = \\{5, 10, 20\\} $ точность ухудшается вместе с уменьшением количества токенов поступающих на вход. \n",
    "\n",
    "![](../images/check_last_n_tokens_quality.png \"Title\") \n",
    "\n",
    "Также интересно, что при удваивании количества итераций при инференсе мы получаем ошибку больше на каждом этапе отбрасывания $ n $ токенов. Это может происходить в результате того, что модели при увеличенном количестве итераций, от изначальной тренировки, более чувствительны к нехватке токенов. "
   ],
   "id": "b68e1f869c6d3437"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bd14b3cee13558ce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e7b30624c58c72b8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "81e05f2216c4c58"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Looped n-layers.\n",
   "id": "43f9972e09aea473"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T05:16:11.930325Z",
     "start_time": "2024-07-29T05:16:05.081700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from models import TransformerModelLoopedLastNTokens\n",
    "from train import get_task_sampler\n",
    "transformer_model = TransformerModelLoopedLastNTokens(\n",
    "    n_dims=2,\n",
    "    n_positions=101,\n",
    "    n = 2,\n",
    "    n_embd=4,\n",
    "    n_layer=1,\n",
    "    n_head=2,\n",
    "    pred_type=\"regression\",\n",
    ").cuda()"
   ],
   "id": "e1b63652da307ec2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 0.00M\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T05:20:29.085244Z",
     "start_time": "2024-07-29T05:20:29.072847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "task_sampler = get_task_sampler(\n",
    "    task_name=\"linear_regression\",\n",
    "    batch_size=1,\n",
    "    n_points=10,\n",
    "    n_dims=2,\n",
    "    n_dims_truncated=3,\n",
    "    device=\"cuda\"\n",
    ")\n",
    "\n",
    "real_task = task_sampler()\n",
    "xs, ys = real_task.xs.float(), real_task.ys.float()\n",
    "n_loops = 3  # K\n",
    "n_loop_window = 20\n",
    "\n",
    "horizon_start = max(0, n_loops - n_loop_window)\n",
    "## forward pass \n",
    "B, n, d_in = xs.shape\n",
    "zs = transformer_model._combine(xs, ys)  # [B, n, d_in], [B, n], [B, n] -> [B, 2n, d_in + 1]"
   ],
   "id": "b6e2a424a7fa5232",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T05:20:30.956929Z",
     "start_time": "2024-07-29T05:20:30.907745Z"
    }
   },
   "cell_type": "code",
   "source": "transformer_model(xs, ys, horizon_start, n_loops)",
   "id": "73eb1eb3b207deae",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.3710, -0.3643, -0.7270, -0.1246, -0.0335, -0.1669, -0.0703, -0.5157,\n",
       "          -0.7283, -0.5444]], device='cuda:0', grad_fn=<SelectBackward0>),\n",
       " tensor([[-0.3710, -0.3643, -0.7270, -0.1246, -0.0335, -0.1669, -0.0703, -0.5157,\n",
       "          -0.7284, -0.5444]], device='cuda:0', grad_fn=<SelectBackward0>),\n",
       " tensor([[-0.3710, -0.3643, -0.7270, -0.1246, -0.0335, -0.1669, -0.0703, -0.5157,\n",
       "          -0.7284, -0.5444]], device='cuda:0', grad_fn=<SelectBackward0>)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T05:20:33.262157Z",
     "start_time": "2024-07-29T05:20:33.251967Z"
    }
   },
   "cell_type": "code",
   "source": "zs",
   "id": "cb8688380cf40703",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5870,  0.1149],\n",
       "         [-0.2003,  0.0000],\n",
       "         [-2.0130, -0.2876],\n",
       "         [ 0.6235,  0.0000],\n",
       "         [ 0.6402, -0.9374],\n",
       "         [ 0.4157,  0.0000],\n",
       "         [-0.6628,  0.1530],\n",
       "         [ 0.0575,  0.0000],\n",
       "         [ 0.7804,  1.3274],\n",
       "         [-0.9673,  0.0000],\n",
       "         [-1.4634,  2.8384],\n",
       "         [-1.3653,  0.0000],\n",
       "         [ 0.0658,  1.4392],\n",
       "         [-0.8736,  0.0000],\n",
       "         [ 0.6056, -0.1975],\n",
       "         [-0.0181,  0.0000],\n",
       "         [-0.1198, -0.3768],\n",
       "         [ 0.2517,  0.0000],\n",
       "         [-0.3114, -0.3883],\n",
       "         [ 0.3016,  0.0000]]], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T05:20:36.799672Z",
     "start_time": "2024-07-29T05:20:36.787456Z"
    }
   },
   "cell_type": "code",
   "source": "transformer_model._read_in(zs), transformer_model._read_in(zs).shape",
   "id": "201384d2f467bd82",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-9.2080e-02, -3.2012e-01, -3.4652e-01,  2.7293e-02],\n",
       "          [-2.1660e-01, -1.8346e-01, -1.9326e-01, -8.6382e-02],\n",
       "          [-4.9213e-01,  1.1829e-01,  1.5017e-01, -3.5361e-01],\n",
       "          [-2.8036e-02, -3.9375e-01, -4.0285e-01,  3.7657e-03],\n",
       "          [ 4.3008e-01, -9.2265e-01, -7.9086e-01, -2.1887e-01],\n",
       "          [-7.5596e-02, -3.4071e-01, -3.4999e-01, -1.8972e-02],\n",
       "          [-3.9658e-01,  2.0201e-02, -1.2983e-02, -1.0036e-01],\n",
       "          [-1.5758e-01, -2.4927e-01, -2.5886e-01, -5.8169e-02],\n",
       "          [-6.3543e-01,  3.0912e-01,  1.0066e-01,  3.3881e-01],\n",
       "          [-3.9215e-01,  1.2325e-02,  1.8709e-03, -1.7031e-01],\n",
       "          [-1.8812e+00,  1.7275e+00,  1.2900e+00,  4.5508e-01],\n",
       "          [-4.8325e-01,  1.1392e-01,  1.0313e-01, -2.1386e-01],\n",
       "          [-8.5315e-01,  5.5408e-01,  3.2821e-01,  2.8738e-01],\n",
       "          [-3.7071e-01, -1.1593e-02, -2.1967e-02, -1.6006e-01],\n",
       "          [ 6.3601e-02, -4.9973e-01, -4.7917e-01, -4.5484e-02],\n",
       "          [-1.7488e-01, -2.2998e-01, -2.3963e-01, -6.6438e-02],\n",
       "          [-1.5569e-02, -4.1489e-01, -3.6800e-01, -1.6779e-01],\n",
       "          [-1.1313e-01, -2.9885e-01, -3.0827e-01, -3.6914e-02],\n",
       "          [-5.3829e-02, -3.7244e-01, -3.2398e-01, -1.9152e-01],\n",
       "          [-1.0171e-01, -3.1159e-01, -3.2096e-01, -3.1455e-02]]],\n",
       "        device='cuda:0', grad_fn=<ViewBackward0>),\n",
       " torch.Size([1, 20, 4]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T05:20:40.460807Z",
     "start_time": "2024-07-29T05:20:40.446147Z"
    }
   },
   "cell_type": "code",
   "source": "x = transformer_model._read_in(zs)",
   "id": "600085d85f782522",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T05:21:06.897333Z",
     "start_time": "2024-07-29T05:21:06.873342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "n = 6\n",
    "print(x.shape)\n",
    "x_mask = torch.zeros((x.shape[0], x.shape[1] - n * 2, x.shape[2])).cuda()\n",
    "print(x_mask.shape)\n",
    "x_n = x[:, :n * 2, :]\n",
    "print(x_n.shape)\n",
    "torch.cat([x_n, x_mask], dim=1)\n"
   ],
   "id": "7f53911f22e80def",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20, 4])\n",
      "torch.Size([1, 8, 4])\n",
      "torch.Size([1, 12, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-9.2080e-02, -3.2012e-01, -3.4652e-01,  2.7293e-02],\n",
       "         [-2.1660e-01, -1.8346e-01, -1.9326e-01, -8.6382e-02],\n",
       "         [-4.9213e-01,  1.1829e-01,  1.5017e-01, -3.5361e-01],\n",
       "         [-2.8036e-02, -3.9375e-01, -4.0285e-01,  3.7657e-03],\n",
       "         [ 4.3008e-01, -9.2265e-01, -7.9086e-01, -2.1887e-01],\n",
       "         [-7.5596e-02, -3.4071e-01, -3.4999e-01, -1.8972e-02],\n",
       "         [-3.9658e-01,  2.0201e-02, -1.2983e-02, -1.0036e-01],\n",
       "         [-1.5758e-01, -2.4927e-01, -2.5886e-01, -5.8169e-02],\n",
       "         [-6.3543e-01,  3.0912e-01,  1.0066e-01,  3.3881e-01],\n",
       "         [-3.9215e-01,  1.2325e-02,  1.8709e-03, -1.7031e-01],\n",
       "         [-1.8812e+00,  1.7275e+00,  1.2900e+00,  4.5508e-01],\n",
       "         [-4.8325e-01,  1.1392e-01,  1.0313e-01, -2.1386e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
       "       device='cuda:0', grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
